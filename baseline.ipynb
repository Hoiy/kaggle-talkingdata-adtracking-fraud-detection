{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lib import load_train, load_test\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_train(nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ip', 'app', 'device', 'os', 'channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns features\n",
    "for col in cat_cols:\n",
    "    log_col = 'log_%s_count'%col\n",
    "    col_count = pd.DataFrame(train.groupby(col).size(), columns=[log_col]).reset_index()\n",
    "    col_count[log_col] = minmax_scale(np.log(col_count[log_col]))\n",
    "    train = pd.merge(train, col_count, on=col, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip features\n",
    "for col in cat_cols[1:]:\n",
    "    log_col = 'log_%s_distinct_count_by_ip'%col\n",
    "    col_count = pd.DataFrame({ log_col: train.groupby('ip')[col].nunique()}).reset_index()\n",
    "    col_count[log_col] = minmax_scale(np.log(col_count[log_col]))\n",
    "    train = pd.merge(train, col_count, on='ip', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build embedding for most occuring 20% cat_cols, default embedding for the remaining 80%\n",
    "EMBEDDING_TOP_QUANTILE = .2\n",
    "embedding_set = {}\n",
    "for col in cat_cols:\n",
    "    log_col = 'log_%s_count'%col\n",
    "    embedding_set[col] = set(train[col][train[log_col] >= train[log_col].quantile(1-EMBEDDING_TOP_QUANTILE)].cat.codes.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def roc_auc_score(y_true, y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    Arguments:\n",
    "        y_pred: `Tensor`. Predicted values.\n",
    "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"RocAucScore\"):\n",
    "\n",
    "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        neg = tf.expand_dims(neg, 1)\n",
    "\n",
    "        # original paper suggests performance is robust to exact parameter choice\n",
    "        gamma = 0.2\n",
    "        p     = 3\n",
    "\n",
    "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "\n",
    "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "\n",
    "        return tf.reduce_sum(tf.pow(-masked, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_1 (MappedEmbed (None, 1, 8)         2736        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_2 (MappedEmbed (None, 1, 8)         24          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_3 (MappedEmbed (None, 1, 8)         16          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_4 (MappedEmbed (None, 1, 8)         16          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_5 (MappedEmbed (None, 1, 8)         24          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8)            0           mapped_embedding_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 8)            0           mapped_embedding_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 8)            0           mapped_embedding_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 8)            0           mapped_embedding_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 8)            0           mapped_embedding_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 49)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1600        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,449\n",
      "Trainable params: 4,449\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Flatten, Activation\n",
    "from keras.layers import Add,Conv1D, MaxPooling1D, Average, Lambda, RepeatVector, LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GRU, Conv1D, Reshape, MaxPooling1D, Concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import non_neg, unit_norm\n",
    "from mlkit.keras import MappedEmbedding\n",
    "\n",
    "DROPOUT=0.5\n",
    "\n",
    "FREE_EMB_SIZE=8\n",
    "\n",
    "zero_one_signals = ['log_%s_count'%col for col in cat_cols] + ['log_%s_distinct_count_by_ip'%col for col in cat_cols[1:]]\n",
    "\n",
    "def get_model():\n",
    "    inputs = []\n",
    "    embs = []\n",
    "    for col in cat_cols:\n",
    "        inp = Input(shape=(1, ), dtype='int32')\n",
    "        emb = Flatten()(MappedEmbedding(embedding_set[col], FREE_EMB_SIZE)(inp))\n",
    "        inputs.append(inp)\n",
    "        embs.append(emb)\n",
    "    \n",
    "    zo_inputs = []\n",
    "    for sig in zero_one_signals:\n",
    "        inp = Input(shape=(1, ))\n",
    "        zo_inputs.append(inp)\n",
    "                \n",
    "    emb = Concatenate()(embs + zo_inputs)\n",
    "    emb = Dense(32, activation='selu')(emb)\n",
    "    final = Dense(1, activation='sigmoid')(emb)\n",
    "    \n",
    "    model = Model(inputs=inputs+zo_inputs, outputs=final)\n",
    "    model.compile(loss=roc_auc_score,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "np.random.seed(777)\n",
    "batch_size = 1024\n",
    "epochs = 2000\n",
    "\n",
    "class ROC_Callback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        super(ROC_Callback, self).__init__()\n",
    "            \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #print(\"keke\", self.model.uses_learning_phase)\n",
    "        #print(\"hmm\", K.set_learning_phase(False))\n",
    "        y_pred_val = self.model.predict(self.x_val, batch_size=batch_size)\n",
    "        #print(\"hmm\", K.set_learning_phase(True))\n",
    "        roc_val = metrics.roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('roc-auc_val: %s' % str(round(roc_val,4)),end=100*' '+'\\n')\n",
    "        #print(self.model.layers[6].get_weights())\n",
    "        #print(self.model.layers[-2].get_weights())\n",
    "        #print(y_pred_val)\n",
    "        return\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16670 samples, validate on 16666 samples\n",
      "Epoch 1/2000\n",
      "16670/16670 [==============================] - 1s 38us/step - loss: 2.6071 - acc: 2.3995e-04 - binary_crossentropy: 0.9156 - val_loss: 4.3943 - val_acc: 0.0013 - val_binary_crossentropy: 0.8497\n",
      "roc-auc_val: 0.5513                                                                                                    \n",
      "Epoch 2/2000\n",
      "16670/16670 [==============================] - 0s 9us/step - loss: 2.1608 - acc: 3.5993e-04 - binary_crossentropy: 0.9063 - val_loss: 4.3825 - val_acc: 0.0036 - val_binary_crossentropy: 0.8439\n",
      "roc-auc_val: 0.5452                                                                                                    \n",
      "Epoch 3/2000\n",
      "16670/16670 [==============================] - 0s 9us/step - loss: 1.8396 - acc: 0.0013 - binary_crossentropy: 0.8908 - val_loss: 4.5034 - val_acc: 0.0094 - val_binary_crossentropy: 0.8379\n",
      "roc-auc_val: 0.5415                                                                                                    \n",
      "Epoch 4/2000\n",
      "16670/16670 [==============================] - 0s 10us/step - loss: 1.5829 - acc: 0.0062 - binary_crossentropy: 0.8747 - val_loss: 4.7388 - val_acc: 0.0380 - val_binary_crossentropy: 0.8189\n",
      "roc-auc_val: 0.5335                                                                                                    \n",
      "Epoch 5/2000\n",
      "16670/16670 [==============================] - 0s 8us/step - loss: 1.3640 - acc: 0.0293 - binary_crossentropy: 0.8454 - val_loss: 5.0933 - val_acc: 0.1145 - val_binary_crossentropy: 0.7963\n",
      "roc-auc_val: 0.5414                                                                                                    \n",
      "Epoch 00005: early stopping\n",
      "0.5452185136270861\n",
      "Train on 33336 samples, validate on 16666 samples\n",
      "Epoch 1/2000\n",
      "33336/33336 [==============================] - 1s 20us/step - loss: 3.3785 - acc: 0.9996 - binary_crossentropy: 0.2775 - val_loss: 6.2147 - val_acc: 0.9992 - val_binary_crossentropy: 0.2599\n",
      "roc-auc_val: 0.633                                                                                                    \n",
      "Epoch 2/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 2.8088 - acc: 0.9996 - binary_crossentropy: 0.2393 - val_loss: 5.6199 - val_acc: 0.9992 - val_binary_crossentropy: 0.2297\n",
      "roc-auc_val: 0.6628                                                                                                    \n",
      "Epoch 3/2000\n",
      "33336/33336 [==============================] - 0s 9us/step - loss: 2.5265 - acc: 0.9996 - binary_crossentropy: 0.2278 - val_loss: 5.1344 - val_acc: 0.9992 - val_binary_crossentropy: 0.2272\n",
      "roc-auc_val: 0.6969                                                                                                    \n",
      "Epoch 4/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 2.2657 - acc: 0.9996 - binary_crossentropy: 0.2391 - val_loss: 4.6459 - val_acc: 0.9992 - val_binary_crossentropy: 0.2448\n",
      "roc-auc_val: 0.7388                                                                                                    \n",
      "Epoch 5/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 1.9623 - acc: 0.9996 - binary_crossentropy: 0.2665 - val_loss: 4.1606 - val_acc: 0.9992 - val_binary_crossentropy: 0.2757\n",
      "roc-auc_val: 0.7782                                                                                                    \n",
      "Epoch 6/2000\n",
      "33336/33336 [==============================] - 0s 9us/step - loss: 1.6289 - acc: 0.9996 - binary_crossentropy: 0.3041 - val_loss: 3.7849 - val_acc: 0.9992 - val_binary_crossentropy: 0.3135\n",
      "roc-auc_val: 0.8105                                                                                                    \n",
      "Epoch 7/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 1.3286 - acc: 0.9996 - binary_crossentropy: 0.3477 - val_loss: 3.5246 - val_acc: 0.9992 - val_binary_crossentropy: 0.3575\n",
      "roc-auc_val: 0.8223                                                                                                    \n",
      "Epoch 8/2000\n",
      "33336/33336 [==============================] - 0s 7us/step - loss: 1.0893 - acc: 0.9996 - binary_crossentropy: 0.3895 - val_loss: 3.3425 - val_acc: 0.9991 - val_binary_crossentropy: 0.3848\n",
      "roc-auc_val: 0.8292                                                                                                    \n",
      "Epoch 9/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 0.9117 - acc: 0.9995 - binary_crossentropy: 0.4096 - val_loss: 3.2038 - val_acc: 0.9990 - val_binary_crossentropy: 0.3980\n",
      "roc-auc_val: 0.8346                                                                                                    \n",
      "Epoch 10/2000\n",
      "33336/33336 [==============================] - 0s 11us/step - loss: 0.7882 - acc: 0.9993 - binary_crossentropy: 0.4164 - val_loss: 3.1028 - val_acc: 0.9990 - val_binary_crossentropy: 0.4017\n",
      "roc-auc_val: 0.8396                                                                                                    \n",
      "Epoch 11/2000\n",
      "33336/33336 [==============================] - 0s 12us/step - loss: 0.7046 - acc: 0.9987 - binary_crossentropy: 0.4163 - val_loss: 3.0014 - val_acc: 0.9989 - val_binary_crossentropy: 0.4009\n",
      "roc-auc_val: 0.8443                                                                                                    \n",
      "Epoch 12/2000\n",
      "33336/33336 [==============================] - 0s 10us/step - loss: 0.6447 - acc: 0.9979 - binary_crossentropy: 0.4162 - val_loss: 2.9193 - val_acc: 0.9985 - val_binary_crossentropy: 0.4052\n",
      "roc-auc_val: 0.8468                                                                                                    \n",
      "Epoch 13/2000\n",
      "33336/33336 [==============================] - 0s 10us/step - loss: 0.6018 - acc: 0.9962 - binary_crossentropy: 0.4168 - val_loss: 2.8374 - val_acc: 0.9984 - val_binary_crossentropy: 0.4073\n",
      "roc-auc_val: 0.8502                                                                                                    \n",
      "Epoch 14/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 0.5661 - acc: 0.9953 - binary_crossentropy: 0.4160 - val_loss: 2.7682 - val_acc: 0.9983 - val_binary_crossentropy: 0.4035\n",
      "roc-auc_val: 0.8544                                                                                                    \n",
      "Epoch 15/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 0.5408 - acc: 0.9954 - binary_crossentropy: 0.4130 - val_loss: 2.7186 - val_acc: 0.9982 - val_binary_crossentropy: 0.4019\n",
      "roc-auc_val: 0.8561                                                                                                    \n",
      "Epoch 16/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 0.5195 - acc: 0.9950 - binary_crossentropy: 0.4098 - val_loss: 2.6774 - val_acc: 0.9981 - val_binary_crossentropy: 0.4003\n",
      "roc-auc_val: 0.8584                                                                                                    \n",
      "Epoch 17/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 0.4988 - acc: 0.9948 - binary_crossentropy: 0.4048 - val_loss: 2.6535 - val_acc: 0.9981 - val_binary_crossentropy: 0.3948\n",
      "roc-auc_val: 0.8601                                                                                                    \n",
      "Epoch 18/2000\n",
      "33336/33336 [==============================] - 0s 8us/step - loss: 0.4819 - acc: 0.9949 - binary_crossentropy: 0.3962 - val_loss: 2.6356 - val_acc: 0.9982 - val_binary_crossentropy: 0.3859\n",
      "roc-auc_val: 0.8622                                                                                                    \n",
      "Epoch 19/2000\n",
      "33336/33336 [==============================] - 0s 10us/step - loss: 0.4665 - acc: 0.9946 - binary_crossentropy: 0.3925 - val_loss: 2.6205 - val_acc: 0.9977 - val_binary_crossentropy: 0.3879\n",
      "roc-auc_val: 0.863                                                                                                    \n",
      "Epoch 20/2000\n",
      "33336/33336 [==============================] - 0s 9us/step - loss: 0.4518 - acc: 0.9945 - binary_crossentropy: 0.3882 - val_loss: 2.6001 - val_acc: 0.9977 - val_binary_crossentropy: 0.3877\n",
      "roc-auc_val: 0.8646                                                                                                    \n",
      "Epoch 21/2000\n",
      "33336/33336 [==============================] - 0s 10us/step - loss: 0.4430 - acc: 0.9937 - binary_crossentropy: 0.3904 - val_loss: 2.5990 - val_acc: 0.9977 - val_binary_crossentropy: 0.3816\n",
      "roc-auc_val: 0.8659                                                                                                    \n",
      "Epoch 22/2000\n",
      "33336/33336 [==============================] - 0s 10us/step - loss: 0.4317 - acc: 0.9941 - binary_crossentropy: 0.3831 - val_loss: 2.5814 - val_acc: 0.9976 - val_binary_crossentropy: 0.3828\n",
      "roc-auc_val: 0.8677                                                                                                    \n",
      "Epoch 23/2000\n",
      "33336/33336 [==============================] - 0s 9us/step - loss: 0.4225 - acc: 0.9932 - binary_crossentropy: 0.3850 - val_loss: 2.5957 - val_acc: 0.9975 - val_binary_crossentropy: 0.3795\n",
      "roc-auc_val: 0.8676                                                                                                    \n",
      "Epoch 24/2000\n",
      "33336/33336 [==============================] - 0s 10us/step - loss: 0.4150 - acc: 0.9933 - binary_crossentropy: 0.3816 - val_loss: 2.5933 - val_acc: 0.9969 - val_binary_crossentropy: 0.3890\n",
      "roc-auc_val: 0.8684                                                                                                    \n",
      "Epoch 25/2000\n",
      "33336/33336 [==============================] - 0s 10us/step - loss: 0.4074 - acc: 0.9915 - binary_crossentropy: 0.3883 - val_loss: 2.6024 - val_acc: 0.9971 - val_binary_crossentropy: 0.3836\n",
      "roc-auc_val: 0.8687                                                                                                    \n",
      "Epoch 00025: early stopping\n",
      "0.8676560933811879\n",
      "Train on 50002 samples, validate on 16666 samples\n",
      "Epoch 1/2000\n",
      "50002/50002 [==============================] - 1s 18us/step - loss: 4.1977 - acc: 0.9422 - binary_crossentropy: 0.6139 - val_loss: 7.3369 - val_acc: 0.9987 - val_binary_crossentropy: 0.5545\n",
      "roc-auc_val: 0.6763                                                                                                    \n",
      "Epoch 2/2000\n",
      "50002/50002 [==============================] - 1s 11us/step - loss: 3.1551 - acc: 0.9993 - binary_crossentropy: 0.5227 - val_loss: 6.6134 - val_acc: 0.9988 - val_binary_crossentropy: 0.5052\n",
      "roc-auc_val: 0.6991                                                                                                    \n",
      "Epoch 3/2000\n",
      "50002/50002 [==============================] - 1s 11us/step - loss: 2.5133 - acc: 0.9991 - binary_crossentropy: 0.4963 - val_loss: 6.1699 - val_acc: 0.9987 - val_binary_crossentropy: 0.4948\n",
      "roc-auc_val: 0.7354                                                                                                    \n",
      "Epoch 4/2000\n",
      "50002/50002 [==============================] - 0s 9us/step - loss: 2.0498 - acc: 0.9985 - binary_crossentropy: 0.4996 - val_loss: 5.9255 - val_acc: 0.9981 - val_binary_crossentropy: 0.5046\n",
      "roc-auc_val: 0.7482                                                                                                    \n",
      "Epoch 5/2000\n",
      "50002/50002 [==============================] - 0s 9us/step - loss: 1.7276 - acc: 0.9979 - binary_crossentropy: 0.5052 - val_loss: 5.8047 - val_acc: 0.9975 - val_binary_crossentropy: 0.5144\n",
      "roc-auc_val: 0.7556                                                                                                    \n",
      "Epoch 6/2000\n",
      "50002/50002 [==============================] - 0s 9us/step - loss: 1.4924 - acc: 0.9954 - binary_crossentropy: 0.5072 - val_loss: 5.7358 - val_acc: 0.9915 - val_binary_crossentropy: 0.5198\n",
      "roc-auc_val: 0.7613                                                                                                    \n",
      "Epoch 7/2000\n",
      "50002/50002 [==============================] - 0s 9us/step - loss: 1.3156 - acc: 0.9930 - binary_crossentropy: 0.5048 - val_loss: 5.7229 - val_acc: 0.9896 - val_binary_crossentropy: 0.5190\n",
      "roc-auc_val: 0.7629                                                                                                    \n",
      "Epoch 8/2000\n",
      "50002/50002 [==============================] - 0s 8us/step - loss: 1.1883 - acc: 0.9912 - binary_crossentropy: 0.4995 - val_loss: 5.7257 - val_acc: 0.9879 - val_binary_crossentropy: 0.5172\n",
      "roc-auc_val: 0.7648                                                                                                    \n",
      "Epoch 9/2000\n",
      "50002/50002 [==============================] - 0s 8us/step - loss: 1.0972 - acc: 0.9898 - binary_crossentropy: 0.4950 - val_loss: 5.7627 - val_acc: 0.9866 - val_binary_crossentropy: 0.5150\n",
      "roc-auc_val: 0.7653                                                                                                    \n",
      "Epoch 10/2000\n",
      "50002/50002 [==============================] - 0s 9us/step - loss: 1.0290 - acc: 0.9857 - binary_crossentropy: 0.4927 - val_loss: 5.7971 - val_acc: 0.9851 - val_binary_crossentropy: 0.5217\n",
      "roc-auc_val: 0.7682                                                                                                    \n",
      "Epoch 00010: early stopping\n",
      "0.762881093491377\n",
      "Train on 66668 samples, validate on 16666 samples\n",
      "Epoch 1/2000\n",
      "66668/66668 [==============================] - 1s 13us/step - loss: 5.6318 - acc: 8.5498e-04 - binary_crossentropy: 1.1406 - val_loss: 9.0635 - val_acc: 0.0247 - val_binary_crossentropy: 0.8222\n",
      "roc-auc_val: 0.6428                                                                                                    \n",
      "Epoch 2/2000\n",
      "66668/66668 [==============================] - 1s 8us/step - loss: 3.9502 - acc: 0.2821 - binary_crossentropy: 0.7451 - val_loss: 5.8252 - val_acc: 0.9621 - val_binary_crossentropy: 0.6085\n",
      "roc-auc_val: 0.8128                                                                                                    \n",
      "Epoch 3/2000\n",
      "66668/66668 [==============================] - 1s 8us/step - loss: 3.2390 - acc: 0.9913 - binary_crossentropy: 0.5546 - val_loss: 4.8350 - val_acc: 0.9954 - val_binary_crossentropy: 0.5242\n",
      "roc-auc_val: 0.8754                                                                                                    \n",
      "Epoch 4/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 2.8449 - acc: 0.9977 - binary_crossentropy: 0.4953 - val_loss: 4.3600 - val_acc: 0.9954 - val_binary_crossentropy: 0.5060\n",
      "roc-auc_val: 0.8944                                                                                                    \n",
      "Epoch 5/2000\n",
      "66668/66668 [==============================] - 1s 8us/step - loss: 2.5755 - acc: 0.9975 - binary_crossentropy: 0.4762 - val_loss: 4.0416 - val_acc: 0.9947 - val_binary_crossentropy: 0.4976\n",
      "roc-auc_val: 0.9048                                                                                                    \n",
      "Epoch 6/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 2.3855 - acc: 0.9967 - binary_crossentropy: 0.4646 - val_loss: 3.8205 - val_acc: 0.9925 - val_binary_crossentropy: 0.5030\n",
      "roc-auc_val: 0.9105                                                                                                    \n",
      "Epoch 7/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 2.2322 - acc: 0.9958 - binary_crossentropy: 0.4625 - val_loss: 3.6467 - val_acc: 0.9911 - val_binary_crossentropy: 0.5005\n",
      "roc-auc_val: 0.9139                                                                                                    \n",
      "Epoch 8/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 2.1166 - acc: 0.9950 - binary_crossentropy: 0.4540 - val_loss: 3.5059 - val_acc: 0.9893 - val_binary_crossentropy: 0.5012\n",
      "roc-auc_val: 0.9173                                                                                                    \n",
      "Epoch 9/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 2.0334 - acc: 0.9943 - binary_crossentropy: 0.4487 - val_loss: 3.3819 - val_acc: 0.9872 - val_binary_crossentropy: 0.5046\n",
      "roc-auc_val: 0.9211                                                                                                    \n",
      "Epoch 10/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.9747 - acc: 0.9908 - binary_crossentropy: 0.4541 - val_loss: 3.2757 - val_acc: 0.9860 - val_binary_crossentropy: 0.5029\n",
      "roc-auc_val: 0.9249                                                                                                    \n",
      "Epoch 11/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.9307 - acc: 0.9911 - binary_crossentropy: 0.4413 - val_loss: 3.1790 - val_acc: 0.9846 - val_binary_crossentropy: 0.4996\n",
      "roc-auc_val: 0.9284                                                                                                    \n",
      "Epoch 12/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.9023 - acc: 0.9904 - binary_crossentropy: 0.4397 - val_loss: 3.1198 - val_acc: 0.9848 - val_binary_crossentropy: 0.4951\n",
      "roc-auc_val: 0.9306                                                                                                    \n",
      "Epoch 13/2000\n",
      "66668/66668 [==============================] - 1s 8us/step - loss: 1.8816 - acc: 0.9903 - binary_crossentropy: 0.4325 - val_loss: 3.0724 - val_acc: 0.9865 - val_binary_crossentropy: 0.4890\n",
      "roc-auc_val: 0.9322                                                                                                    \n",
      "Epoch 14/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.8626 - acc: 0.9915 - binary_crossentropy: 0.4196 - val_loss: 3.0267 - val_acc: 0.9881 - val_binary_crossentropy: 0.4791\n",
      "roc-auc_val: 0.9337                                                                                                    \n",
      "Epoch 15/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.8495 - acc: 0.9910 - binary_crossentropy: 0.4163 - val_loss: 3.0026 - val_acc: 0.9877 - val_binary_crossentropy: 0.4787\n",
      "roc-auc_val: 0.9337                                                                                                    \n",
      "Epoch 16/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.8384 - acc: 0.9908 - binary_crossentropy: 0.4129 - val_loss: 2.9638 - val_acc: 0.9884 - val_binary_crossentropy: 0.4707\n",
      "roc-auc_val: 0.9356                                                                                                    \n",
      "Epoch 17/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.8293 - acc: 0.9912 - binary_crossentropy: 0.4075 - val_loss: 2.9368 - val_acc: 0.9884 - val_binary_crossentropy: 0.4691\n",
      "roc-auc_val: 0.9366                                                                                                    \n",
      "Epoch 18/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.8212 - acc: 0.9918 - binary_crossentropy: 0.3991 - val_loss: 2.9194 - val_acc: 0.9904 - val_binary_crossentropy: 0.4538\n",
      "roc-auc_val: 0.9374                                                                                                    \n",
      "Epoch 19/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.8145 - acc: 0.9923 - binary_crossentropy: 0.3925 - val_loss: 2.9240 - val_acc: 0.9894 - val_binary_crossentropy: 0.4590\n",
      "roc-auc_val: 0.9364                                                                                                    \n",
      "Epoch 20/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.8075 - acc: 0.9913 - binary_crossentropy: 0.3944 - val_loss: 2.8928 - val_acc: 0.9895 - val_binary_crossentropy: 0.4560\n",
      "roc-auc_val: 0.9376                                                                                                    \n",
      "Epoch 21/2000\n",
      "66668/66668 [==============================] - 1s 8us/step - loss: 1.8018 - acc: 0.9909 - binary_crossentropy: 0.3938 - val_loss: 2.8750 - val_acc: 0.9894 - val_binary_crossentropy: 0.4562\n",
      "roc-auc_val: 0.9385                                                                                                    \n",
      "Epoch 22/2000\n",
      "66668/66668 [==============================] - 1s 10us/step - loss: 1.8010 - acc: 0.9914 - binary_crossentropy: 0.3867 - val_loss: 2.8669 - val_acc: 0.9906 - val_binary_crossentropy: 0.4480\n",
      "roc-auc_val: 0.9389                                                                                                    \n",
      "Epoch 23/2000\n",
      "66668/66668 [==============================] - 1s 9us/step - loss: 1.7928 - acc: 0.9915 - binary_crossentropy: 0.3837 - val_loss: 2.8542 - val_acc: 0.9915 - val_binary_crossentropy: 0.4410\n",
      "roc-auc_val: 0.94                                                                                                    \n",
      "Epoch 24/2000\n",
      "66668/66668 [==============================] - 0s 7us/step - loss: 1.7846 - acc: 0.9919 - binary_crossentropy: 0.3779 - val_loss: 2.8613 - val_acc: 0.9918 - val_binary_crossentropy: 0.4384\n",
      "roc-auc_val: 0.9395                                                                                                    \n",
      "Epoch 25/2000\n",
      "66668/66668 [==============================] - 1s 9us/step - loss: 1.7857 - acc: 0.9920 - binary_crossentropy: 0.3758 - val_loss: 2.8600 - val_acc: 0.9917 - val_binary_crossentropy: 0.4385\n",
      "roc-auc_val: 0.9389                                                                                                    \n",
      "Epoch 26/2000\n",
      "66668/66668 [==============================] - 1s 9us/step - loss: 1.7806 - acc: 0.9924 - binary_crossentropy: 0.3712 - val_loss: 2.8664 - val_acc: 0.9920 - val_binary_crossentropy: 0.4323\n",
      "roc-auc_val: 0.9383                                                                                                    \n",
      "Epoch 00026: early stopping\n",
      "0.940024889499206\n",
      "Train on 83334 samples, validate on 16666 samples\n",
      "Epoch 1/2000\n",
      "83334/83334 [==============================] - 1s 12us/step - loss: 4.6855 - acc: 0.7193 - binary_crossentropy: 0.6491 - val_loss: 21.9020 - val_acc: 0.9920 - val_binary_crossentropy: 0.4361\n",
      "roc-auc_val: 0.946                                                                                                    \n",
      "Epoch 2/2000\n",
      "83334/83334 [==============================] - 1s 7us/step - loss: 3.5014 - acc: 0.9987 - binary_crossentropy: 0.4125 - val_loss: 20.1676 - val_acc: 0.9888 - val_binary_crossentropy: 0.4460\n",
      "roc-auc_val: 0.9545                                                                                                    \n",
      "Epoch 3/2000\n",
      "83334/83334 [==============================] - 1s 7us/step - loss: 3.0231 - acc: 0.9972 - binary_crossentropy: 0.4226 - val_loss: 18.8977 - val_acc: 0.9834 - val_binary_crossentropy: 0.4778\n",
      "roc-auc_val: 0.9576                                                                                                    \n",
      "Epoch 4/2000\n",
      "83334/83334 [==============================] - 1s 7us/step - loss: 2.7481 - acc: 0.9963 - binary_crossentropy: 0.4283 - val_loss: 17.9777 - val_acc: 0.9794 - val_binary_crossentropy: 0.5002\n",
      "roc-auc_val: 0.9565                                                                                                    \n",
      "Epoch 5/2000\n",
      "83334/83334 [==============================] - 1s 8us/step - loss: 2.5623 - acc: 0.9945 - binary_crossentropy: 0.4330 - val_loss: 17.2461 - val_acc: 0.9740 - val_binary_crossentropy: 0.5169\n",
      "roc-auc_val: 0.9561                                                                                                    \n",
      "Epoch 6/2000\n",
      "83334/83334 [==============================] - 1s 7us/step - loss: 2.4186 - acc: 0.9921 - binary_crossentropy: 0.4370 - val_loss: 16.8010 - val_acc: 0.9647 - val_binary_crossentropy: 0.5350\n",
      "roc-auc_val: 0.9556                                                                                                    \n",
      "Epoch 7/2000\n",
      "83334/83334 [==============================] - 1s 7us/step - loss: 2.2795 - acc: 0.9859 - binary_crossentropy: 0.4510 - val_loss: 16.4991 - val_acc: 0.9464 - val_binary_crossentropy: 0.5511\n",
      "roc-auc_val: 0.955                                                                                                    \n",
      "Epoch 8/2000\n",
      "83334/83334 [==============================] - 1s 7us/step - loss: 2.1648 - acc: 0.9823 - binary_crossentropy: 0.4515 - val_loss: 16.2178 - val_acc: 0.9330 - val_binary_crossentropy: 0.5587\n",
      "roc-auc_val: 0.9545                                                                                                    \n",
      "Epoch 9/2000\n",
      "83334/83334 [==============================] - 1s 6us/step - loss: 2.0800 - acc: 0.9839 - binary_crossentropy: 0.4447 - val_loss: 15.9820 - val_acc: 0.9341 - val_binary_crossentropy: 0.5542\n",
      "roc-auc_val: 0.9539                                                                                                    \n",
      "Epoch 10/2000\n",
      "83334/83334 [==============================] - 1s 7us/step - loss: 2.0272 - acc: 0.9837 - binary_crossentropy: 0.4378 - val_loss: 15.7992 - val_acc: 0.9170 - val_binary_crossentropy: 0.5616\n",
      "roc-auc_val: 0.9536                                                                                                    \n",
      "Epoch 11/2000\n",
      "83334/83334 [==============================] - 1s 8us/step - loss: 1.9914 - acc: 0.9832 - binary_crossentropy: 0.4345 - val_loss: 15.6858 - val_acc: 0.9187 - val_binary_crossentropy: 0.5583\n",
      "roc-auc_val: 0.9532                                                                                                    \n",
      "Epoch 12/2000\n",
      "83334/83334 [==============================] - 1s 8us/step - loss: 1.9665 - acc: 0.9840 - binary_crossentropy: 0.4285 - val_loss: 15.5970 - val_acc: 0.9204 - val_binary_crossentropy: 0.5542\n",
      "roc-auc_val: 0.9526                                                                                                    \n",
      "Epoch 13/2000\n",
      "83334/83334 [==============================] - 1s 8us/step - loss: 1.9466 - acc: 0.9857 - binary_crossentropy: 0.4204 - val_loss: 15.5617 - val_acc: 0.9278 - val_binary_crossentropy: 0.5523\n",
      "roc-auc_val: 0.9521                                                                                                    \n",
      "Epoch 14/2000\n",
      "83334/83334 [==============================] - 1s 7us/step - loss: 1.9320 - acc: 0.9841 - binary_crossentropy: 0.4205 - val_loss: 15.5388 - val_acc: 0.9185 - val_binary_crossentropy: 0.5530\n",
      "roc-auc_val: 0.9519                                                                                                    \n",
      "Epoch 15/2000\n",
      "83334/83334 [==============================] - 1s 8us/step - loss: 1.9188 - acc: 0.9833 - binary_crossentropy: 0.4194 - val_loss: 15.5521 - val_acc: 0.9146 - val_binary_crossentropy: 0.5542\n",
      "roc-auc_val: 0.9516                                                                                                    \n",
      "Epoch 16/2000\n",
      "83334/83334 [==============================] - 1s 6us/step - loss: 1.9079 - acc: 0.9841 - binary_crossentropy: 0.4149 - val_loss: 15.6023 - val_acc: 0.9302 - val_binary_crossentropy: 0.5461\n",
      "roc-auc_val: 0.9514                                                                                                    \n",
      "Epoch 17/2000\n",
      "83334/83334 [==============================] - 1s 6us/step - loss: 1.8980 - acc: 0.9850 - binary_crossentropy: 0.4101 - val_loss: 15.6671 - val_acc: 0.9261 - val_binary_crossentropy: 0.5472\n",
      "roc-auc_val: 0.951                                                                                                    \n",
      "Epoch 00017: early stopping\n",
      "0.9518918514812482\n",
      "[0.5452185136270861, 0.8676560933811879, 0.762881093491377, 0.940024889499206, 0.9518918514812482]\n",
      "0.8135344882960209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "from keras import backend as K\n",
    "\n",
    "scores = []\n",
    "fold = 0\n",
    "for train_index, test_index in tscv.split(train):\n",
    "    K.clear_session()\n",
    "    \n",
    "    fold = fold + 1\n",
    "    \n",
    "    val_data = ([train.iloc[test_index][col].cat.codes for col in cat_cols] + \\\n",
    "                [train.iloc[test_index][col] for col in zero_one_signals], train.iloc[test_index]['is_attributed'])\n",
    "    \n",
    "    model = get_model()\n",
    "    file_path=\"model/weights_base_%d.best.hdf5\"%fold\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_loss', save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3, verbose=1)\n",
    "    \n",
    "    callbacks_list = [checkpoint, early, ROC_Callback(val_data)]\n",
    "    \n",
    "    model.fit(\n",
    "        [train.iloc[train_index][col].cat.codes for col in cat_cols] + \\\n",
    "        [train.iloc[train_index][col] for col in zero_one_signals],\n",
    "        train.iloc[train_index]['is_attributed'],\n",
    "        validation_data=val_data,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    \n",
    "    model = keras.models.load_model(file_path, custom_objects={'roc_auc_score': roc_auc_score, 'MappedEmbedding': MappedEmbedding})\n",
    "    #print(\"huehue\", model.uses_learning_phase)\n",
    "    #print(\"umm\", K.learning_phase())\n",
    "    #print(model.layers[6].get_weights())\n",
    "    #print(model.layers[-2].get_weights())\n",
    "    pred = model.predict(val_data[0], batch_size=batch_size)\n",
    "    score = metrics.roc_auc_score(val_data[1], pred)\n",
    "    #print(pred)\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_2():\n",
    "    inp = Input(shape=(1, ), dtype='int32')\n",
    "    emb = Flatten()(MappedEmbedding({1,2,0}, 10)(inp))    \n",
    "    emb = Dense(32, activation='selu')(emb)\n",
    "    final = Dense(1, activation='sigmoid')(emb)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=final)\n",
    "    model.compile(loss=roc_auc_score,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_6 (MappedEmbed (None, 1, 8)         2736        input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_7 (MappedEmbed (None, 1, 8)         24          input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_8 (MappedEmbed (None, 1, 8)         16          input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_9 (MappedEmbed (None, 1, 8)         16          input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mapped_embedding_10 (MappedEmbe (None, 1, 8)         24          input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 8)            0           mapped_embedding_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 8)            0           mapped_embedding_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 8)            0           mapped_embedding_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 8)            0           mapped_embedding_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 8)            0           mapped_embedding_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 49)           0           flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 input_20[0][0]                   \n",
      "                                                                 input_21[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "                                                                 input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "                                                                 input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "                                                                 input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           1600        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,449\n",
      "Trainable params: 4,449\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - binary_crossentropy: 0.7129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d7454a8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = [0]\n",
    "model.fit([train.iloc[test_index][col].cat.codes for col in cat_cols] + \\\n",
    "                [train.iloc[test_index][col] for col in zero_one_signals], train.iloc[test_index]['is_attributed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03214715, -0.16870683,  0.10500881, -0.10001985,  0.03555877,\n",
       "          0.15037759, -0.17230658,  0.14564137],\n",
       "        [-0.04172715,  0.13678333, -0.06963095,  0.00411195,  0.009346  ,\n",
       "         -0.0918017 ,  0.08801676, -0.08637956],\n",
       "        [-0.03043789,  0.04082359,  0.00169233, -0.02834171, -0.00818788,\n",
       "          0.07432535, -0.01728122,  0.02455434]], dtype=float32)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[6].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31607026],\n",
       "       [0.31892636],\n",
       "       [0.4487195 ],\n",
       "       [0.32271594],\n",
       "       [0.29100475],\n",
       "       [0.33080772]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = [1,2,3,4,5,6]\n",
    "model.predict([train.iloc[test_index][col].cat.codes for col in cat_cols] + \\\n",
    "                [train.iloc[test_index][col] for col in zero_one_signals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.models.load_model('test.h5',  custom_objects={'roc_auc_score': roc_auc_score, 'MappedEmbedding': MappedEmbedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.23144867, -0.12154941, -0.27586138, ...,  0.16279975,\n",
       "         -0.0250041 , -0.16909423],\n",
       "        [ 0.01860329,  0.00501241, -0.12694931, ...,  0.14690122,\n",
       "         -0.20517546, -0.01793425],\n",
       "        [-0.07709707,  0.0790906 ,  0.07163449, ..., -0.11180533,\n",
       "         -0.18836391,  0.32591605],\n",
       "        ...,\n",
       "        [-0.26686233,  0.04572774, -0.00395839, ..., -0.02381474,\n",
       "          0.09236376, -0.26723504],\n",
       "        [ 0.10473236, -0.12107859,  0.06303404, ..., -0.17733975,\n",
       "         -0.23299211,  0.11016463],\n",
       "        [-0.18442461, -0.01593718, -0.13219152, ..., -0.06198743,\n",
       "          0.291708  ,  0.23921354]], dtype=float32),\n",
       " array([-0.06696922,  0.04911892, -0.06250626,  0.03865436,  0.08189637,\n",
       "         0.05301873,  0.04343357,  0.05812351,  0.01407997,  0.09384292,\n",
       "        -0.0411795 , -0.05950984,  0.0006912 , -0.09105127,  0.15746282,\n",
       "        -0.11641625, -0.03445261,  0.01963986, -0.0724998 ,  0.06706317,\n",
       "        -0.03925785, -0.08805388, -0.00085283,  0.09721431, -0.04846101,\n",
       "         0.0376652 ,  0.04913663, -0.09093124,  0.18222399, -0.08083589,\n",
       "         0.06813299, -0.07109571], dtype=float32)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.layers[-2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31607026],\n",
       "       [0.31892636],\n",
       "       [0.4487195 ],\n",
       "       [0.32271594],\n",
       "       [0.29100475],\n",
       "       [0.33080772]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.predict([train.iloc[test_index][col].cat.codes for col in cat_cols] + \\\n",
    "                [train.iloc[test_index][col] for col in zero_one_signals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
